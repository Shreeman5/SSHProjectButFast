# Configuration for Attack Data Pipeline
# Update these paths to match your system

[paths]
# Your JSON file (in same directory)
json_file = ./ipinfo.json

# Your CSV folder (contains clem, utah, wisc subdirectories)
csv_directory = ./csv_files/

# Where to save output
output_directory = ./parquet_output

# DuckDB database location
duckdb_path = ./attack_data.db


[processing]
# Number of rows to process at once (adjust based on your RAM)
# 100000 = ~100MB per chunk for your data
chunk_size = 100000

# Compression for Parquet files (snappy is fast, gzip is smaller)
compression = snappy
